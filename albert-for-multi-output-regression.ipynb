{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6636824,"sourceType":"datasetVersion","datasetId":3831388}],"dockerImageVersionId":30558,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install accelerate --upgrade\n","metadata":{"execution":{"iopub.status.busy":"2023-11-12T08:25:54.879915Z","iopub.execute_input":"2023-11-12T08:25:54.880243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" #pip install transformers[torch] accelerate>=0.20.1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pip install transformers[torch] accelerate -U","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pip install accelerate -U","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pip install --upgrade transformers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pip install -U huggingface_hub","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pip install sacremoses","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch, os\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import Dataset\nimport matplotlib.pyplot as plt\nfrom transformers import pipeline, TrainingArguments, Trainer\n#from sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom torch import cuda\nfrom sklearn.preprocessing import StandardScaler\n\nfrom transformers import AlbertConfig, AlbertTokenizerFast, AlbertForSequenceClassification\nfrom transformers import DataCollatorWithPadding\nfrom torch.utils.data import DataLoader","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-11T11:52:40.76874Z","iopub.execute_input":"2023-11-11T11:52:40.769414Z","iopub.status.idle":"2023-11-11T11:52:43.713544Z","shell.execute_reply.started":"2023-11-11T11:52:40.769374Z","shell.execute_reply":"2023-11-11T11:52:43.71241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if cuda.is_available() else 'cpu'\nprint(device)\n\nif torch.cuda.is_available():\n    # Print the name of the GPU device\n    print('GPU:', torch.cuda.get_device_name(0))\nelse:\n    print('No GPU available. Switch to a GPU accelerator in Kaggle settings.')","metadata":{"execution":{"iopub.status.busy":"2023-11-11T11:52:46.997713Z","iopub.execute_input":"2023-11-11T11:52:46.998708Z","iopub.status.idle":"2023-11-11T11:52:47.030689Z","shell.execute_reply.started":"2023-11-11T11:52:46.998673Z","shell.execute_reply":"2023-11-11T11:52:47.029715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/big-five-dataset/big_five_train_set.csv')\nvalidation_data = pd.read_csv('/kaggle/input/big-five-dataset/big_five_val_set.csv')\ntest_data = pd.read_csv('/kaggle/input/big-five-dataset/big_five_eval_set.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-11T11:52:50.60563Z","iopub.execute_input":"2023-11-11T11:52:50.606447Z","iopub.status.idle":"2023-11-11T11:52:50.841235Z","shell.execute_reply.started":"2023-11-11T11:52:50.606413Z","shell.execute_reply":"2023-11-11T11:52:50.84044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data.shape)\nprint(validation_data.shape)\nprint(test_data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T11:52:52.912243Z","iopub.execute_input":"2023-11-11T11:52:52.9126Z","iopub.status.idle":"2023-11-11T11:52:52.918081Z","shell.execute_reply.started":"2023-11-11T11:52:52.912571Z","shell.execute_reply":"2023-11-11T11:52:52.917108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.columns.values","metadata":{"execution":{"iopub.status.busy":"2023-11-11T11:52:54.329833Z","iopub.execute_input":"2023-11-11T11:52:54.330648Z","iopub.status.idle":"2023-11-11T11:52:54.337023Z","shell.execute_reply.started":"2023-11-11T11:52:54.330617Z","shell.execute_reply":"2023-11-11T11:52:54.336162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import nn","metadata":{"execution":{"iopub.status.busy":"2023-11-11T11:52:55.765922Z","iopub.execute_input":"2023-11-11T11:52:55.766589Z","iopub.status.idle":"2023-11-11T11:52:55.771247Z","shell.execute_reply.started":"2023-11-11T11:52:55.766556Z","shell.execute_reply":"2023-11-11T11:52:55.770194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a custom dataset\nclass PersonalityDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_length=128):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        text = self.data.iloc[idx]['text']\n        traits = torch.tensor(self.data.iloc[idx][['agreeableness', 'openness', 'conscientiousness', 'extraversion', 'neuroticism']], dtype=torch.float)\n        encoding = self.tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=self.max_length)\n        input_ids, attention_mask = encoding[\"input_ids\"].squeeze(), encoding[\"attention_mask\"].squeeze()\n        labels = data[traits.view(1, 5)]  # Reshape to (1, 5)\n        return {\n            'input_ids': input_ids,\n            'attention_mask': attention_mask,\n            'labels': labels\n        }\n","metadata":{"execution":{"iopub.status.busy":"2023-11-11T11:52:58.152269Z","iopub.execute_input":"2023-11-11T11:52:58.152625Z","iopub.status.idle":"2023-11-11T11:52:58.161204Z","shell.execute_reply.started":"2023-11-11T11:52:58.152596Z","shell.execute_reply":"2023-11-11T11:52:58.159941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AlbertTokenizerFast.from_pretrained(\"albert-base-v2\",  max_length = 256)\nconfig = AlbertConfig.from_pretrained('albert-base-v2', num_labels=5)\nmodel = AlbertForPreTraining.from_pretrained(\"albert-base-v2\", num_labels=5)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T11:53:00.168282Z","iopub.execute_input":"2023-11-11T11:53:00.168647Z","iopub.status.idle":"2023-11-11T11:53:01.423769Z","shell.execute_reply.started":"2023-11-11T11:53:00.168619Z","shell.execute_reply":"2023-11-11T11:53:01.422796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_regression_targets = 5  # Change this to match your number of regression targets\nmodel","metadata":{"execution":{"iopub.status.busy":"2023-11-11T11:53:06.163588Z","iopub.execute_input":"2023-11-11T11:53:06.16397Z","iopub.status.idle":"2023-11-11T11:53:06.170814Z","shell.execute_reply.started":"2023-11-11T11:53:06.163941Z","shell.execute_reply":"2023-11-11T11:53:06.169964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from transformers import AlbertModel, AlbertForSequenceClassification\n\nnum_regression_targets = 5\n\nfrom transformers import AlbertModel, AlbertConfig\nimport torch.nn as nn\n\nclass CustomAlbertForRegression(nn.Module):\n    def __init__(self, config, num_regression_targets):\n        super(CustomAlbertForRegression, self).__init__()\n        self.albert = AlbertModel(config)\n        \n        # Add your linear layers\n        self.linear1 = nn.Linear(config.hidden_size, 128)\n        self.relu1 = nn.ReLU()\n        self.linear2 = nn.Linear(128, 128)\n        self.tanh1 = nn.Tanh()\n        self.linear3 = nn.Linear(128, num_regression_targets)\n\n    def forward(self, input_ids, attention_mask, token_type_ids=None, position_ids=None, head_mask=None, labels=None):\n        outputs = self.albert(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n            position_ids=position_ids,\n            head_mask=head_mask\n        )\n\n        # Extract the last hidden state from the ALBERT model\n        last_hidden_state = outputs.last_hidden_state\n\n        # Calculate the mean of last_hidden_state across the sequence dimension\n        pooled_output = torch.mean(last_hidden_state, dim=1)\n\n        # Apply your additional linear layers\n        linear_output = self.linear1(pooled_output)\n        linear_output = self.relu1(linear_output)\n        linear_output = self.linear2(linear_output)\n        linear_output = self.tanh1(linear_output)\n        regression_output = self.linear3(linear_output)\n\n        if labels is not None:\n            # Calculate the mean squared error loss if targets are provided\n            loss = torch.nn.functional.mse_loss(regression_output, labels)\n            return {'loss': loss, 'logits': regression_output}\n        else:\n            # Return predictions as a dictionary with \"logits\" key\n            return {'logits': regression_output}\n\n\nfrom transformers import AlbertTokenizerFast, AlbertConfig\n\ntokenizer = AlbertTokenizerFast.from_pretrained('albert-base-v2', num_labels = 5)\nconfig = AlbertConfig.from_pretrained('albert-base-v2', num_labels = 5)\nnum_regression_targets = 5\ncustom_model = CustomAlbertForRegression(config, num_regression_targets)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-11T12:09:08.368848Z","iopub.execute_input":"2023-11-11T12:09:08.369266Z","iopub.status.idle":"2023-11-11T12:09:08.898371Z","shell.execute_reply.started":"2023-11-11T12:09:08.369234Z","shell.execute_reply":"2023-11-11T12:09:08.897384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"","metadata":{"execution":{"iopub.status.busy":"2023-11-09T20:41:31.578714Z","iopub.execute_input":"2023-11-09T20:41:31.579492Z","iopub.status.idle":"2023-11-09T20:41:31.64381Z","shell.execute_reply.started":"2023-11-09T20:41:31.579456Z","shell.execute_reply":"2023-11-09T20:41:31.642552Z"}}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T12:09:13.048879Z","iopub.execute_input":"2023-11-11T12:09:13.049299Z","iopub.status.idle":"2023-11-11T12:09:13.07407Z","shell.execute_reply.started":"2023-11-11T12:09:13.049271Z","shell.execute_reply":"2023-11-11T12:09:13.07306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_texts = list(train_data.text)\nval_texts = list(validation_data.text)\ntest_texts = list(test_data.text)\ntrain_labels = list(train_data[['agreeableness', 'openness', 'conscientiousness', 'extraversion', 'neuroticism']].values)\nval_labels = list(validation_data[['agreeableness', 'openness', 'conscientiousness', 'extraversion', 'neuroticism']].values)\ntest_labels = list(test_data[['agreeableness', 'openness', 'conscientiousness', 'extraversion', 'neuroticism']].values)\n\ntrain_labels = np.array(train_labels, dtype=np.float32)\nval_labels = np.array(val_labels, dtype=np.float32)\ntest_labels = np.array(test_labels, dtype=np.float32)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T12:09:28.777117Z","iopub.execute_input":"2023-11-11T12:09:28.777971Z","iopub.status.idle":"2023-11-11T12:09:28.812213Z","shell.execute_reply.started":"2023-11-11T12:09:28.777928Z","shell.execute_reply":"2023-11-11T12:09:28.811204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_labels.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-11T12:09:30.457Z","iopub.execute_input":"2023-11-11T12:09:30.45736Z","iopub.status.idle":"2023-11-11T12:09:30.465118Z","shell.execute_reply.started":"2023-11-11T12:09:30.457333Z","shell.execute_reply":"2023-11-11T12:09:30.464051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_encodings = tokenizer(train_texts, truncation=True, padding=True)\nval_encodings = tokenizer(val_texts, truncation=True, padding=True)\ntest_encodings = tokenizer(test_texts, truncation=True, padding=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T12:09:31.892265Z","iopub.execute_input":"2023-11-11T12:09:31.893352Z","iopub.status.idle":"2023-11-11T12:09:36.15311Z","shell.execute_reply.started":"2023-11-11T12:09:31.893317Z","shell.execute_reply":"2023-11-11T12:09:36.152111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_encodings.keys())\nprint(len(train_encodings['input_ids']))\nprint(len(train_encodings['input_ids'][0]))\nprint(train_encodings['input_ids'][0][:10])\nprint(train_encodings['attention_mask'][0][:10])\n\nprint(train_labels[0].dtype)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-11T12:09:37.80671Z","iopub.execute_input":"2023-11-11T12:09:37.807112Z","iopub.status.idle":"2023-11-11T12:09:37.81734Z","shell.execute_reply.started":"2023-11-11T12:09:37.807081Z","shell.execute_reply":"2023-11-11T12:09:37.816131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataLoader(PersonalityDataset):\n    \"\"\"\n    Custom Dataset class for handling tokenized text data and corresponding labels.\n    Inherits from torch.utils.data.Dataset.\n    \"\"\"\n    def __init__(self, encodings, labels):\n        \"\"\"\n        Initializes the DataLoader class with encodings and labels.\n\n        Args:\n            encodings (dict): A dictionary containing tokenized input text data\n                              (e.g., 'input_ids', 'token_type_ids', 'attention_mask').\n            labels (list): A list of integer labels for the input text data.\n        \"\"\"\n        self.encodings = encodings\n        self.labels = labels\n        \n    def __getitem__(self, idx):\n        \"\"\"\n        Returns a dictionary containing tokenized data and the corresponding label for a given index.\n\n        Args:\n            idx (int): The index of the data item to retrieve.\n\n        Returns:\n            item (dict): A dictionary containing the tokenized data and the corresponding label.\n        \"\"\"\n        # Retrieve tokenized data for the given index\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        # Add the label for the given index to the item dictionary\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        \"\"\"\n        Returns the number of data items in the dataset.\n\n        Returns:\n            (int): The number of data items in the dataset.\n        \"\"\"\n        return len(self.labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T12:09:38.101678Z","iopub.execute_input":"2023-11-11T12:09:38.102834Z","iopub.status.idle":"2023-11-11T12:09:38.112719Z","shell.execute_reply.started":"2023-11-11T12:09:38.102792Z","shell.execute_reply":"2023-11-11T12:09:38.111648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_loader = DataLoader(train_encodings, train_labels)\nval_loader = DataLoader(val_encodings, val_labels)\ntest_loader = DataLoader(test_encodings, test_labels)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-11T12:09:39.888724Z","iopub.execute_input":"2023-11-11T12:09:39.889094Z","iopub.status.idle":"2023-11-11T12:09:39.960899Z","shell.execute_reply.started":"2023-11-11T12:09:39.889065Z","shell.execute_reply":"2023-11-11T12:09:39.959712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(val_loader))  # Number of data points in the training dataset\nprint(len(val_loader[0]['labels']))  # Number of targets for the first data point\nprint(val_loader[0]['labels'])\n","metadata":{"execution":{"iopub.status.busy":"2023-11-11T12:09:41.374715Z","iopub.execute_input":"2023-11-11T12:09:41.375488Z","iopub.status.idle":"2023-11-11T12:09:41.386397Z","shell.execute_reply.started":"2023-11-11T12:09:41.375456Z","shell.execute_reply":"2023-11-11T12:09:41.384873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\n\ndef compute_metrics_for_regression(eval_pred):\n    logits, labels = eval_pred\n    labels = labels.reshape(-1, 5)\n    print(\"Labels shape:\", labels.shape)\n    print(\"Logits shape:\", logits.shape)\n    print(labels)\n\n    # Calculate regression metrics\n    mse = mean_squared_error(labels, logits, multioutput='raw_values')\n    mae = mean_absolute_error(labels, logits, multioutput='raw_values')\n    r2 = r2_score(labels, logits, multioutput='raw_values')\n    # Compute accuracy \n    rmse = np.sqrt(mse)\n    single_squared_errors = ((logits - labels)**2)\n    accuracy = [sum(e < 0.25) / len(e) for e in single_squared_errors.T]\n\n    # Calculate the mean of all metrics\n    metrics = {\n        \"mse\": mse.mean(),\n        \"rmse\": rmse.mean(),\n        \"mae\": mae.mean(),\n        \"r2\": r2.mean(),\n        \"accuracy\": sum(accuracy) / len(accuracy)\n    }\n    \n    return metrics\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-11T12:09:42.568467Z","iopub.execute_input":"2023-11-11T12:09:42.568806Z","iopub.status.idle":"2023-11-11T12:09:42.579369Z","shell.execute_reply.started":"2023-11-11T12:09:42.568781Z","shell.execute_reply":"2023-11-11T12:09:42.57832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#base_model = \"albert\"\nlearning_rate = 2e-5\nmax_length = 256\nbatch_size = 4\nepochs = 3\n\nfrom transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    # The output directory where the model predictions and checkpoints will be written\n    output_dir=\"./models/albert-fine-tuned-regression\",\n    do_train=True,\n    do_eval=True,\n    learning_rate=learning_rate,\n    per_device_train_batch_size=batch_size,\n    per_gpu_eval_batch_size=batch_size,\n    num_train_epochs=epochs,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=2,\n    metric_for_best_model=\"mse\",\n    load_best_model_at_end=True,\n    weight_decay=0.01\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T12:09:51.667986Z","iopub.execute_input":"2023-11-11T12:09:51.668372Z","iopub.status.idle":"2023-11-11T12:09:51.679121Z","shell.execute_reply.started":"2023-11-11T12:09:51.668339Z","shell.execute_reply":"2023-11-11T12:09:51.677995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\n\nclass RegressionTrainer(Trainer):\n\n    def compute_loss(self, custom_model, inputs, return_outputs=False):\n        try:\n            labels = inputs.pop(\"labels\", None)\n            print(\"Labels:\", labels)\n            if labels is not None:\n                outputs = custom_model(**inputs)\n                logits = outputs.logits\n                loss = torch.nn.functional.mse_loss(logits, labels)\n                return (loss, outputs) if return_outputs else loss\n            else:\n                print(\"Labels are None in compute_loss\")\n                return None\n        except Exception as e:\n            print(\"Error in compute_loss:\", e)\n            print(\"Inputs:\", inputs)\n            return None\n","metadata":{"execution":{"iopub.status.busy":"2023-11-11T12:09:53.962573Z","iopub.execute_input":"2023-11-11T12:09:53.963431Z","iopub.status.idle":"2023-11-11T12:09:53.972041Z","shell.execute_reply.started":"2023-11-11T12:09:53.963397Z","shell.execute_reply":"2023-11-11T12:09:53.970958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n  \n       ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_model.to(\"cuda:0\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-11T12:09:57.117142Z","iopub.execute_input":"2023-11-11T12:09:57.118027Z","iopub.status.idle":"2023-11-11T12:09:57.127591Z","shell.execute_reply.started":"2023-11-11T12:09:57.117993Z","shell.execute_reply":"2023-11-11T12:09:57.126477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_regression_targets = 5  # Change this to match your number of regression targets\n\ntrainer = Trainer(\n    model=custom_model,\n    args=training_args,\n    train_dataset=train_loader,\n    eval_dataset = val_loader,\n    compute_metrics = compute_metrics_for_regression\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-11T12:10:12.600304Z","iopub.execute_input":"2023-11-11T12:10:12.600671Z","iopub.status.idle":"2023-11-11T12:10:12.612064Z","shell.execute_reply.started":"2023-11-11T12:10:12.600642Z","shell.execute_reply":"2023-11-11T12:10:12.610879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Before training, inspect the evaluation dataset\nfor i, data in enumerate(val_loader):\n    input_ids = data['input_ids']\n    attention_mask = data['attention_mask']\n    labels = data['labels']\nfor i, data in enumerate(train_loader):\n\n    # Print shapes and labels for debugging\n    print(f\"Sample {i + 1} - Input IDs shape:\", input_ids.shape)\n    print(f\"Sample {i + 1} - Input IDs :\", input_ids)\n    print(f\"Sample {i + 1} - Attention Mask shape:\", attention_mask.shape)\n    print(f\"Sample {i + 1} - Attention Mask:\", attention_mask)\n    print(f\"Sample {i + 1} - Labels shape:\", labels.shape)\n    print(f\"Sample {i + 1} - Labels values:\", labels)\n    print(f\"Sample {i + 1} - Labels values:\", data['labels'])\n    break\n# ... Rest of your code ...","metadata":{"execution":{"iopub.status.busy":"2023-11-11T12:10:14.987463Z","iopub.execute_input":"2023-11-11T12:10:14.988115Z","iopub.status.idle":"2023-11-11T12:10:16.283578Z","shell.execute_reply.started":"2023-11-11T12:10:14.988081Z","shell.execute_reply":"2023-11-11T12:10:16.282404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-11-11T12:10:17.43532Z","iopub.execute_input":"2023-11-11T12:10:17.435921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Evaluate on validation dataset\neval_result = trainer.evaluate(val_loader)\n\nprint(\"Evaluation result:\")\nfor key, value in eval_result.items():\n    print(f\"{key}: {value}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T22:04:50.961579Z","iopub.status.idle":"2023-11-09T22:04:50.962137Z","shell.execute_reply.started":"2023-11-09T22:04:50.961845Z","shell.execute_reply":"2023-11-09T22:04:50.961875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# New text input\nnew_text = 'I hate to go out and party'\n\n# Tokenize the input text\nencoding = tokenizer(new_text, return_tensors='pt', padding='max_length', truncation=True, max_length=128)\n\n# Move the input tensors to the GPU (cuda:0)\ninput_ids = encoding[\"input_ids\"].to(\"cuda:0\")\nattention_mask = encoding[\"attention_mask\"].to(\"cuda:0\")\n\n# Move the model to the GPU (cuda:0)\nmodel.to(\"cuda:0\")\n\n# Pass the tokenized input through the model to obtain predictions\noutputs = model(input_ids, attention_mask=attention_mask)\n\n# Get the predicted scores\npredicted_scores = outputs.logits.squeeze().tolist()\n\nprint(\"Predicted Scores:\", predicted_scores)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T22:04:50.963252Z","iopub.status.idle":"2023-11-09T22:04:50.964868Z","shell.execute_reply.started":"2023-11-09T22:04:50.964569Z","shell.execute_reply":"2023-11-09T22:04:50.964598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the labels (traits)\nlabels = ['agreeableness', 'openness', 'conscientiousness', 'extraversion', 'neuroticism']\n\n# Get the predicted scores\npredicted_scores = outputs.logits.squeeze().tolist()\n\n# Create a dictionary to associate the labels with the predicted scores\npredicted_scores_dict = dict(zip(labels, predicted_scores))\n\nprint(\"Predicted Scores:\")\nfor trait, score in predicted_scores_dict.items():\n    print(f\"{trait}: {score}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}